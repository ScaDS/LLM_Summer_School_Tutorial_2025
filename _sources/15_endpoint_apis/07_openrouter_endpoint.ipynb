{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87404224-b84b-409f-8683-c4a243d29722",
   "metadata": {},
   "source": [
    "# OpenRouter endpoint\n",
    "In this notebook we will use the [OpenRouter LLM service](https://openrouter.ai/) infrastructure. Before you can access it, you need to create an API key and store it as `OPENROUTER_API_KEY`. You will see that also this method uses the OpenAI API and we change the `base_url`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "752e974d-9aaf-44aa-80fb-01a042cf5774",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.74.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab55e229-93b9-4e9b-974d-037002690bf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prompt_openrouter(prompt:str, model=\"google/gemini-2.5-pro-preview\"):\n",
    "    \"\"\"A prompt helper function that sends a message to Openrouter\n",
    "    and returns only the text response.\n",
    "    \"\"\"\n",
    "    # setup connection to the LLM-server\n",
    "    client = openai.OpenAI(\n",
    "        base_url=\"https://openrouter.ai/api/v1\",\n",
    "        api_key=os.environ.get('OPENROUTER_API_KEY')\n",
    "    )\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages= [{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    # extract answer\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7654a20-a307-4b26-8d25-bef20b70224e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi there! How can I help you today?'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_openrouter(\"Hi!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578e9edd-b58f-4fd0-a56d-1966105221dc",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "List the models available in the blablador endpoint and try them out by specifying them when calling `prompt_blablador()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05171ba7-a775-41c5-954d-7d4fc2b5b625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-ai/yi-large\n",
      "aetherwiing/mn-starcannon-12b\n",
      "agentica-org/deepcoder-14b-preview:free\n",
      "ai21/jamba-1.6-large\n",
      "ai21/jamba-1.6-mini\n",
      "aion-labs/aion-1.0\n",
      "aion-labs/aion-1.0-mini\n",
      "aion-labs/aion-rp-llama-3.1-8b\n",
      "alfredpros/codellama-7b-instruct-solidity\n",
      "all-hands/openhands-lm-32b-v0.1\n",
      "alpindale/goliath-120b\n",
      "alpindale/magnum-72b\n",
      "amazon/nova-lite-v1\n",
      "amazon/nova-micro-v1\n",
      "amazon/nova-pro-v1\n",
      "anthracite-org/magnum-v2-72b\n",
      "anthracite-org/magnum-v4-72b\n",
      "anthropic/claude-2\n",
      "anthropic/claude-2.0\n",
      "anthropic/claude-2.0:beta\n",
      "anthropic/claude-2.1\n",
      "anthropic/claude-2.1:beta\n",
      "anthropic/claude-2:beta\n",
      "anthropic/claude-3-haiku\n",
      "anthropic/claude-3-haiku:beta\n",
      "anthropic/claude-3-opus\n",
      "anthropic/claude-3-opus:beta\n",
      "anthropic/claude-3-sonnet\n",
      "anthropic/claude-3-sonnet:beta\n",
      "anthropic/claude-3.5-haiku\n",
      "anthropic/claude-3.5-haiku-20241022\n",
      "anthropic/claude-3.5-haiku-20241022:beta\n",
      "anthropic/claude-3.5-haiku:beta\n",
      "anthropic/claude-3.5-sonnet\n",
      "anthropic/claude-3.5-sonnet-20240620\n",
      "anthropic/claude-3.5-sonnet-20240620:beta\n",
      "anthropic/claude-3.5-sonnet:beta\n",
      "anthropic/claude-3.7-sonnet\n",
      "anthropic/claude-3.7-sonnet:beta\n",
      "anthropic/claude-3.7-sonnet:thinking\n",
      "anthropic/claude-opus-4\n",
      "anthropic/claude-sonnet-4\n",
      "arcee-ai/arcee-blitz\n",
      "arcee-ai/caller-large\n",
      "arcee-ai/coder-large\n",
      "arcee-ai/maestro-reasoning\n",
      "arcee-ai/spotlight\n",
      "arcee-ai/virtuoso-large\n",
      "arcee-ai/virtuoso-medium-v2\n",
      "arliai/qwq-32b-arliai-rpr-v1:free\n",
      "cognitivecomputations/dolphin-mixtral-8x22b\n",
      "cognitivecomputations/dolphin3.0-mistral-24b:free\n",
      "cognitivecomputations/dolphin3.0-r1-mistral-24b:free\n",
      "cohere/command\n",
      "cohere/command-a\n",
      "cohere/command-r\n",
      "cohere/command-r-03-2024\n",
      "cohere/command-r-08-2024\n",
      "cohere/command-r-plus\n",
      "cohere/command-r-plus-04-2024\n",
      "cohere/command-r-plus-08-2024\n",
      "cohere/command-r7b-12-2024\n",
      "deepseek/deepseek-chat\n",
      "deepseek/deepseek-chat-v3-0324\n",
      "deepseek/deepseek-chat-v3-0324:free\n",
      "deepseek/deepseek-chat:free\n",
      "deepseek/deepseek-prover-v2\n",
      "deepseek/deepseek-prover-v2:free\n",
      "deepseek/deepseek-r1\n",
      "deepseek/deepseek-r1-0528\n",
      "deepseek/deepseek-r1-0528-qwen3-8b\n",
      "deepseek/deepseek-r1-0528-qwen3-8b:free\n",
      "deepseek/deepseek-r1-0528:free\n",
      "deepseek/deepseek-r1-distill-llama-70b\n",
      "deepseek/deepseek-r1-distill-llama-70b:free\n",
      "deepseek/deepseek-r1-distill-llama-8b\n",
      "deepseek/deepseek-r1-distill-qwen-1.5b\n",
      "deepseek/deepseek-r1-distill-qwen-14b\n",
      "deepseek/deepseek-r1-distill-qwen-14b:free\n",
      "deepseek/deepseek-r1-distill-qwen-32b\n",
      "deepseek/deepseek-r1-distill-qwen-32b:free\n",
      "deepseek/deepseek-r1-distill-qwen-7b\n",
      "deepseek/deepseek-r1-zero:free\n",
      "deepseek/deepseek-r1:free\n",
      "deepseek/deepseek-v3-base:free\n",
      "eleutherai/llemma_7b\n",
      "eva-unit-01/eva-llama-3.33-70b\n",
      "eva-unit-01/eva-qwen-2.5-32b\n",
      "eva-unit-01/eva-qwen-2.5-72b\n",
      "featherless/qwerky-72b:free\n",
      "google/gemini-2.0-flash-001\n",
      "google/gemini-2.0-flash-exp:free\n",
      "google/gemini-2.0-flash-lite-001\n",
      "google/gemini-2.5-flash-preview\n",
      "google/gemini-2.5-flash-preview-05-20\n",
      "google/gemini-2.5-flash-preview-05-20:thinking\n",
      "google/gemini-2.5-flash-preview:thinking\n",
      "google/gemini-2.5-pro-exp-03-25\n",
      "google/gemini-2.5-pro-preview\n",
      "google/gemini-flash-1.5\n",
      "google/gemini-flash-1.5-8b\n",
      "google/gemini-pro-1.5\n",
      "google/gemma-2-27b-it\n",
      "google/gemma-2-9b-it\n",
      "google/gemma-2-9b-it:free\n",
      "google/gemma-2b-it\n",
      "google/gemma-3-12b-it\n",
      "google/gemma-3-12b-it:free\n",
      "google/gemma-3-1b-it:free\n",
      "google/gemma-3-27b-it\n",
      "google/gemma-3-27b-it:free\n",
      "google/gemma-3-4b-it\n",
      "google/gemma-3-4b-it:free\n",
      "google/gemma-3n-e4b-it:free\n",
      "gryphe/mythomax-l2-13b\n",
      "inception/mercury-coder-small-beta\n",
      "infermatic/mn-inferor-12b\n",
      "inflection/inflection-3-pi\n",
      "inflection/inflection-3-productivity\n",
      "liquid/lfm-3b\n",
      "liquid/lfm-40b\n",
      "liquid/lfm-7b\n",
      "mancer/weaver\n",
      "meta-llama/llama-2-70b-chat\n",
      "meta-llama/llama-3-70b-instruct\n",
      "meta-llama/llama-3-8b-instruct\n",
      "meta-llama/llama-3.1-405b\n",
      "meta-llama/llama-3.1-405b-instruct\n",
      "meta-llama/llama-3.1-405b:free\n",
      "meta-llama/llama-3.1-70b-instruct\n",
      "meta-llama/llama-3.1-8b-instruct\n",
      "meta-llama/llama-3.1-8b-instruct:free\n",
      "meta-llama/llama-3.2-11b-vision-instruct\n",
      "meta-llama/llama-3.2-11b-vision-instruct:free\n",
      "meta-llama/llama-3.2-1b-instruct\n",
      "meta-llama/llama-3.2-1b-instruct:free\n",
      "meta-llama/llama-3.2-3b-instruct\n",
      "meta-llama/llama-3.2-3b-instruct:free\n",
      "meta-llama/llama-3.2-90b-vision-instruct\n",
      "meta-llama/llama-3.3-70b-instruct\n",
      "meta-llama/llama-3.3-70b-instruct:free\n",
      "meta-llama/llama-3.3-8b-instruct:free\n",
      "meta-llama/llama-4-maverick\n",
      "meta-llama/llama-4-maverick:free\n",
      "meta-llama/llama-4-scout\n",
      "meta-llama/llama-4-scout:free\n",
      "meta-llama/llama-guard-2-8b\n",
      "meta-llama/llama-guard-3-8b\n",
      "meta-llama/llama-guard-4-12b\n",
      "microsoft/mai-ds-r1:free\n",
      "microsoft/phi-3-medium-128k-instruct\n",
      "microsoft/phi-3-mini-128k-instruct\n",
      "microsoft/phi-3.5-mini-128k-instruct\n",
      "microsoft/phi-4\n",
      "microsoft/phi-4-multimodal-instruct\n",
      "microsoft/phi-4-reasoning-plus\n",
      "microsoft/phi-4-reasoning-plus:free\n",
      "microsoft/phi-4-reasoning:free\n",
      "microsoft/wizardlm-2-8x22b\n",
      "minimax/minimax-01\n",
      "mistralai/codestral-2501\n",
      "mistralai/devstral-small\n",
      "mistralai/devstral-small:free\n",
      "mistralai/ministral-3b\n",
      "mistralai/ministral-8b\n",
      "mistralai/mistral-7b-instruct\n",
      "mistralai/mistral-7b-instruct-v0.1\n",
      "mistralai/mistral-7b-instruct-v0.2\n",
      "mistralai/mistral-7b-instruct-v0.3\n",
      "mistralai/mistral-7b-instruct:free\n",
      "mistralai/mistral-large\n",
      "mistralai/mistral-large-2407\n",
      "mistralai/mistral-large-2411\n",
      "mistralai/mistral-medium\n",
      "mistralai/mistral-medium-3\n",
      "mistralai/mistral-nemo\n",
      "mistralai/mistral-nemo:free\n",
      "mistralai/mistral-saba\n",
      "mistralai/mistral-small\n",
      "mistralai/mistral-small-24b-instruct-2501\n",
      "mistralai/mistral-small-24b-instruct-2501:free\n",
      "mistralai/mistral-small-3.1-24b-instruct\n",
      "mistralai/mistral-small-3.1-24b-instruct:free\n",
      "mistralai/mistral-tiny\n",
      "mistralai/mixtral-8x22b-instruct\n",
      "mistralai/mixtral-8x7b-instruct\n",
      "mistralai/pixtral-12b\n",
      "mistralai/pixtral-large-2411\n",
      "moonshotai/kimi-vl-a3b-thinking:free\n",
      "moonshotai/moonlight-16b-a3b-instruct:free\n",
      "neversleep/llama-3-lumimaid-70b\n",
      "neversleep/llama-3-lumimaid-8b\n",
      "neversleep/llama-3.1-lumimaid-70b\n",
      "neversleep/llama-3.1-lumimaid-8b\n",
      "neversleep/noromaid-20b\n",
      "nothingiisreal/mn-celeste-12b\n",
      "nousresearch/deephermes-3-llama-3-8b-preview:free\n",
      "nousresearch/deephermes-3-mistral-24b-preview:free\n",
      "nousresearch/hermes-2-pro-llama-3-8b\n",
      "nousresearch/hermes-3-llama-3.1-405b\n",
      "nousresearch/hermes-3-llama-3.1-70b\n",
      "nousresearch/nous-hermes-2-mixtral-8x7b-dpo\n",
      "nvidia/llama-3.1-nemotron-70b-instruct\n",
      "nvidia/llama-3.1-nemotron-ultra-253b-v1\n",
      "nvidia/llama-3.1-nemotron-ultra-253b-v1:free\n",
      "nvidia/llama-3.3-nemotron-super-49b-v1\n",
      "nvidia/llama-3.3-nemotron-super-49b-v1:free\n",
      "open-r1/olympiccoder-32b:free\n",
      "openai/chatgpt-4o-latest\n",
      "openai/codex-mini\n",
      "openai/gpt-3.5-turbo\n",
      "openai/gpt-3.5-turbo-0125\n",
      "openai/gpt-3.5-turbo-0613\n",
      "openai/gpt-3.5-turbo-1106\n",
      "openai/gpt-3.5-turbo-16k\n",
      "openai/gpt-3.5-turbo-instruct\n",
      "openai/gpt-4\n",
      "openai/gpt-4-0314\n",
      "openai/gpt-4-1106-preview\n",
      "openai/gpt-4-32k\n",
      "openai/gpt-4-32k-0314\n",
      "openai/gpt-4-turbo\n",
      "openai/gpt-4-turbo-preview\n",
      "openai/gpt-4.1\n",
      "openai/gpt-4.1-mini\n",
      "openai/gpt-4.1-nano\n",
      "openai/gpt-4.5-preview\n",
      "openai/gpt-4o\n",
      "openai/gpt-4o-2024-05-13\n",
      "openai/gpt-4o-2024-08-06\n",
      "openai/gpt-4o-2024-11-20\n",
      "openai/gpt-4o-mini\n",
      "openai/gpt-4o-mini-2024-07-18\n",
      "openai/gpt-4o-mini-search-preview\n",
      "openai/gpt-4o-search-preview\n",
      "openai/gpt-4o:extended\n",
      "openai/o1\n",
      "openai/o1-mini\n",
      "openai/o1-mini-2024-09-12\n",
      "openai/o1-preview\n",
      "openai/o1-preview-2024-09-12\n",
      "openai/o1-pro\n",
      "openai/o3\n",
      "openai/o3-mini\n",
      "openai/o3-mini-high\n",
      "openai/o4-mini\n",
      "openai/o4-mini-high\n",
      "opengvlab/internvl3-14b:free\n",
      "opengvlab/internvl3-2b:free\n",
      "openrouter/auto\n",
      "perplexity/llama-3.1-sonar-large-128k-online\n",
      "perplexity/llama-3.1-sonar-small-128k-online\n",
      "perplexity/r1-1776\n",
      "perplexity/sonar\n",
      "perplexity/sonar-deep-research\n",
      "perplexity/sonar-pro\n",
      "perplexity/sonar-reasoning\n",
      "perplexity/sonar-reasoning-pro\n",
      "pygmalionai/mythalion-13b\n",
      "qwen/qwen-2-72b-instruct\n",
      "qwen/qwen-2.5-72b-instruct\n",
      "qwen/qwen-2.5-72b-instruct:free\n",
      "qwen/qwen-2.5-7b-instruct\n",
      "qwen/qwen-2.5-7b-instruct:free\n",
      "qwen/qwen-2.5-coder-32b-instruct\n",
      "qwen/qwen-2.5-coder-32b-instruct:free\n",
      "qwen/qwen-2.5-vl-7b-instruct\n",
      "qwen/qwen-2.5-vl-7b-instruct:free\n",
      "qwen/qwen-max\n",
      "qwen/qwen-plus\n",
      "qwen/qwen-turbo\n",
      "qwen/qwen-vl-max\n",
      "qwen/qwen-vl-plus\n",
      "qwen/qwen2.5-vl-32b-instruct\n",
      "qwen/qwen2.5-vl-32b-instruct:free\n",
      "qwen/qwen2.5-vl-3b-instruct:free\n",
      "qwen/qwen2.5-vl-72b-instruct\n",
      "qwen/qwen2.5-vl-72b-instruct:free\n",
      "qwen/qwen3-14b\n",
      "qwen/qwen3-14b:free\n",
      "qwen/qwen3-235b-a22b\n",
      "qwen/qwen3-235b-a22b:free\n",
      "qwen/qwen3-30b-a3b\n",
      "qwen/qwen3-30b-a3b:free\n",
      "qwen/qwen3-32b\n",
      "qwen/qwen3-32b:free\n",
      "qwen/qwen3-8b\n",
      "qwen/qwen3-8b:free\n",
      "qwen/qwq-32b\n",
      "qwen/qwq-32b-preview\n",
      "qwen/qwq-32b:free\n",
      "raifle/sorcererlm-8x22b\n",
      "rekaai/reka-flash-3:free\n",
      "sao10k/fimbulvetr-11b-v2\n",
      "sao10k/l3-euryale-70b\n",
      "sao10k/l3-lunaris-8b\n",
      "sao10k/l3.1-euryale-70b\n",
      "sao10k/l3.3-euryale-70b\n",
      "sarvamai/sarvam-m\n",
      "sarvamai/sarvam-m:free\n",
      "scb10x/llama3.1-typhoon2-70b-instruct\n",
      "scb10x/llama3.1-typhoon2-8b-instruct\n",
      "shisa-ai/shisa-v2-llama3.3-70b:free\n",
      "sophosympatheia/midnight-rose-70b\n",
      "thedrummer/anubis-pro-105b-v1\n",
      "thedrummer/rocinante-12b\n",
      "thedrummer/skyfall-36b-v2\n",
      "thedrummer/unslopnemo-12b\n",
      "thedrummer/valkyrie-49b-v1\n",
      "thudm/glm-4-32b\n",
      "thudm/glm-4-32b:free\n",
      "thudm/glm-z1-32b\n",
      "thudm/glm-z1-32b:free\n",
      "thudm/glm-z1-rumination-32b\n",
      "tngtech/deepseek-r1t-chimera:free\n",
      "undi95/remm-slerp-l2-13b\n",
      "undi95/toppy-m-7b\n",
      "x-ai/grok-2-1212\n",
      "x-ai/grok-2-vision-1212\n",
      "x-ai/grok-3-beta\n",
      "x-ai/grok-3-mini-beta\n",
      "x-ai/grok-beta\n",
      "x-ai/grok-vision-beta\n"
     ]
    }
   ],
   "source": [
    "client = openai.OpenAI()\n",
    "client.base_url = \"https://openrouter.ai/api/v1\"\n",
    "client.api_key = os.environ.get('OPENROUTER_API_KEY')\n",
    "\n",
    "print(\"\\n\".join(sorted([model.id for model in client.models.list().data])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e810ee2-4d22-42f6-add5-532cf95b4b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
